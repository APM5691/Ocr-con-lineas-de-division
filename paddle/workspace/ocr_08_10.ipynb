{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ff38bbbc-c227-475c-9181-97ff56f5d977",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Librerias Cargadas\n"
     ]
    }
   ],
   "source": [
    "from paddleocr import PaddleOCR\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import unicodedata\n",
    "import json\n",
    "import re\n",
    "import cv2\n",
    "import os\n",
    "import re\n",
    "\n",
    "pd.set_option('future.no_silent_downcasting', True)\n",
    "\n",
    "print(\"Librerias Cargadas\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2b9ccefe-aec5-45a5-911f-1745cb335035",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'paddle' has no attribute 'device'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 7\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m#ocr = PaddleOCR(\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;66;03m#    use_doc_orientation_classify=False, \u001b[39;00m\n\u001b[1;32m      3\u001b[0m  \u001b[38;5;66;03m#   use_doc_unwarping=False, \u001b[39;00m\n\u001b[1;32m      4\u001b[0m  \u001b[38;5;66;03m#   use_textline_orientation=False) # text detection + text recognition\u001b[39;00m\n\u001b[1;32m      5\u001b[0m \n\u001b[1;32m      6\u001b[0m \u001b[38;5;66;03m# text image preprocessing + text detection + textline orientation classification + text recognition\u001b[39;00m\n\u001b[0;32m----> 7\u001b[0m ocr \u001b[38;5;241m=\u001b[39m \u001b[43mPaddleOCR\u001b[49m\u001b[43m(\u001b[49m\u001b[43muse_doc_orientation_classify\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43muse_doc_unwarping\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlang\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mes\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m      9\u001b[0m \u001b[38;5;66;03m# ocr = PaddleOCR(use_doc_orientation_classify=False, use_doc_unwarping=False) # text detection + textline orientation classification + text recognition\u001b[39;00m\n\u001b[1;32m     10\u001b[0m \u001b[38;5;66;03m# ocr = PaddleOCR(\u001b[39;00m\n\u001b[1;32m     11\u001b[0m \u001b[38;5;66;03m#     text_detection_model_name=\"PP-OCRv5_mobile_det\",\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[38;5;66;03m#     use_doc_unwarping=False,\u001b[39;00m\n\u001b[1;32m     15\u001b[0m \u001b[38;5;66;03m#     use_textline_orientation=False) # Switch to PP-OCRv5_mobile models\u001b[39;00m\n",
      "File \u001b[0;32m/usr/local/lib/python3.11/dist-packages/paddleocr/_pipelines/ocr.py:163\u001b[0m, in \u001b[0;36mPaddleOCR.__init__\u001b[0;34m(self, doc_orientation_classify_model_name, doc_orientation_classify_model_dir, doc_unwarping_model_name, doc_unwarping_model_dir, text_detection_model_name, text_detection_model_dir, textline_orientation_model_name, textline_orientation_model_dir, textline_orientation_batch_size, text_recognition_model_name, text_recognition_model_dir, text_recognition_batch_size, use_doc_orientation_classify, use_doc_unwarping, use_textline_orientation, text_det_limit_side_len, text_det_limit_type, text_det_thresh, text_det_box_thresh, text_det_unclip_ratio, text_det_input_shape, text_rec_score_thresh, return_word_box, text_rec_input_shape, lang, ocr_version, **kwargs)\u001b[0m\n\u001b[1;32m    159\u001b[0m         base_params[name] \u001b[38;5;241m=\u001b[39m val\n\u001b[1;32m    161\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_params \u001b[38;5;241m=\u001b[39m params\n\u001b[0;32m--> 163\u001b[0m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__init__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mbase_params\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.11/dist-packages/paddleocr/_pipelines/base.py:67\u001b[0m, in \u001b[0;36mPaddleXPipelineWrapper.__init__\u001b[0;34m(self, paddlex_config, **common_args)\u001b[0m\n\u001b[1;32m     63\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_common_args \u001b[38;5;241m=\u001b[39m parse_common_args(\n\u001b[1;32m     64\u001b[0m     common_args, default_enable_hpi\u001b[38;5;241m=\u001b[39m_DEFAULT_ENABLE_HPI\n\u001b[1;32m     65\u001b[0m )\n\u001b[1;32m     66\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_merged_paddlex_config \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_merged_paddlex_config()\n\u001b[0;32m---> 67\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpaddlex_pipeline \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_create_paddlex_pipeline\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.11/dist-packages/paddleocr/_pipelines/base.py:103\u001b[0m, in \u001b[0;36mPaddleXPipelineWrapper._create_paddlex_pipeline\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    102\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_create_paddlex_pipeline\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m--> 103\u001b[0m     kwargs \u001b[38;5;241m=\u001b[39m \u001b[43mprepare_common_init_args\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_common_args\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    104\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    105\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m create_pipeline(config\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_merged_paddlex_config, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m/usr/local/lib/python3.11/dist-packages/paddleocr/_common_args.py:63\u001b[0m, in \u001b[0;36mprepare_common_init_args\u001b[0;34m(model_name, common_args)\u001b[0m\n\u001b[1;32m     61\u001b[0m device \u001b[38;5;241m=\u001b[39m common_args[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdevice\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m     62\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m device \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m---> 63\u001b[0m     device \u001b[38;5;241m=\u001b[39m \u001b[43mget_default_device\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     64\u001b[0m device_type, _ \u001b[38;5;241m=\u001b[39m parse_device(device)\n\u001b[1;32m     66\u001b[0m init_kwargs \u001b[38;5;241m=\u001b[39m {}\n",
      "File \u001b[0;32m/usr/local/lib/python3.11/dist-packages/paddlex/utils/device.py:44\u001b[0m, in \u001b[0;36mget_default_device\u001b[0;34m()\u001b[0m\n\u001b[1;32m     41\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mget_default_device\u001b[39m():\n\u001b[1;32m     42\u001b[0m     \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpaddle\u001b[39;00m\n\u001b[0;32m---> 44\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[43mpaddle\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdevice\u001b[49m\u001b[38;5;241m.\u001b[39mis_compiled_with_cuda() \u001b[38;5;129;01mand\u001b[39;00m paddle\u001b[38;5;241m.\u001b[39mdevice\u001b[38;5;241m.\u001b[39mcuda\u001b[38;5;241m.\u001b[39mdevice_count() \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m     45\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m constr_device(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgpu\u001b[39m\u001b[38;5;124m\"\u001b[39m, [\u001b[38;5;241m0\u001b[39m])\n\u001b[1;32m     46\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[0;31mAttributeError\u001b[0m: module 'paddle' has no attribute 'device'"
     ]
    }
   ],
   "source": [
    "#ocr = PaddleOCR(\n",
    "#    use_doc_orientation_classify=False, \n",
    " #   use_doc_unwarping=False, \n",
    " #   use_textline_orientation=False) # text detection + text recognition\n",
    "\n",
    "# text image preprocessing + text detection + textline orientation classification + text recognition\n",
    "ocr = PaddleOCR(use_doc_orientation_classify=False, use_doc_unwarping=False, lang=\"es\")\n",
    "\n",
    "# ocr = PaddleOCR(use_doc_orientation_classify=False, use_doc_unwarping=False) # text detection + textline orientation classification + text recognition\n",
    "# ocr = PaddleOCR(\n",
    "#     text_detection_model_name=\"PP-OCRv5_mobile_det\",\n",
    "#     text_recognition_model_name=\"PP-OCRv5_mobile_rec\",\n",
    "#     use_doc_orientation_classify=False,\n",
    "#     use_doc_unwarping=False,\n",
    "#     use_textline_orientation=False) # Switch to PP-OCRv5_mobile models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8d4cc65-f5e5-4922-8479-307048afdbff",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "image_dir = \"./imagenes\"  # ruta a tu carpeta con imágenes\n",
    "image_extensions = [\".jpg\", \".jpeg\", \".png\", \".bmp\"]\n",
    "\n",
    "# Filtramos solo imágenes\n",
    "image_files = sorted(\n",
    "    [os.path.join(image_dir, f) \n",
    "     for f in os.listdir(image_dir) \n",
    "     if os.path.splitext(f)[1].lower() in image_extensions],\n",
    "    key=lambda x: int(os.path.splitext(os.path.basename(x))[0])\n",
    ")\n",
    "\n",
    "print(str(len(image_files))+\" Imagenes Cargadas\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01532597-82c0-4985-b3b2-9521343dfe8a",
   "metadata": {},
   "source": [
    "# Tal vez mejorar, si se divide con lineas, o limites"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d915f874-1dec-45b7-a670-cf6e909495cb",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def ocr_to_multidimensional_sections(result, line_gap=6.5, cortes=None):\n",
    "    texts = result[\"rec_texts\"]\n",
    "    boxes = result[\"rec_boxes\"]\n",
    "\n",
    "    # Extraer coordenadas y asociar texto\n",
    "    data = []\n",
    "    for text, box in zip(texts, boxes):\n",
    "        x_min, y_min = box[0], box[1]  # esquina superior izq\n",
    "        text = clean_text_simple(text)\n",
    "        data.append({\"text\": text, \"x\": x_min, \"y\": y_min})\n",
    "\n",
    "    # Ordenar primero por Y (vertical) y luego por X (horizontal)\n",
    "    data = sorted(data, key=lambda d: (d[\"y\"], d[\"x\"]))\n",
    "\n",
    "    # Agrupamos por líneas (Y)\n",
    "    ordered_lines = []\n",
    "    current_line = []\n",
    "    last_y = None\n",
    "\n",
    "    for item in data:\n",
    "        if last_y is None or abs(item[\"y\"] - last_y) <= line_gap:\n",
    "            current_line.append(item)\n",
    "        else:\n",
    "            ordered_lines.append(current_line)\n",
    "            current_line = [item]\n",
    "        last_y = item[\"y\"]\n",
    "\n",
    "    if current_line:\n",
    "        ordered_lines.append(current_line)\n",
    "\n",
    "    # Si no se pasan cortes, devolvemos normal\n",
    "    if not cortes:\n",
    "        max_len = max(len(line) for line in ordered_lines)\n",
    "        ordered_filled = [\n",
    "            [i[\"text\"] for i in line] + [\"\"] * (max_len - len(line))\n",
    "            for line in ordered_lines\n",
    "        ]\n",
    "        return pd.DataFrame(ordered_filled)\n",
    "\n",
    "    # --- Usar cortes en X para dividir en secciones ---\n",
    "    cortes = sorted(cortes)  # [178, 286, 373] por ejemplo\n",
    "    n_sections = len(cortes) + 1\n",
    "\n",
    "    all_rows = []\n",
    "    for line in ordered_lines:\n",
    "        row = [\"\"] * n_sections\n",
    "        for item in line:\n",
    "            x = item[\"x\"]\n",
    "            text = item[\"text\"]\n",
    "\n",
    "            # Buscar en qué sección cae\n",
    "            section_idx = 0\n",
    "            for c in cortes:\n",
    "                if x > c:\n",
    "                    section_idx += 1\n",
    "                else:\n",
    "                    break\n",
    "            row[section_idx] += (\" \" + text if row[section_idx] else text)\n",
    "\n",
    "        all_rows.append(row)\n",
    "\n",
    "    df = pd.DataFrame(all_rows)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4e50d03-aaaa-4189-aaa2-286aed08bd84",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_text_simple(text):\n",
    "    if not isinstance(text, str):\n",
    "        return text\n",
    "     # lista por defecto a eliminar (puedes ampliarla)\n",
    "    default_remove = [\"continua...\", \"continua\", \"ejemplo\", \"borrar\"]\n",
    "    removes = default_remove\n",
    "\n",
    "    s = text.strip()\n",
    "\n",
    "    # normalizar y eliminar diacríticos (á -> a, ñ -> n, etc.)\n",
    "    s = unicodedata.normalize(\"NFKD\", s)\n",
    "    s = s.encode(\"ascii\", \"ignore\").decode(\"ascii\")\n",
    "\n",
    "    # eliminar apostrofes rectos y curvos y guion bajo\n",
    "    s = re.sub(r\"[\\'\\u2019_]\", \"\", s)\n",
    "\n",
    "    # construir patrón para eliminar palabras/frases como palabras completas\n",
    "    # normalizamos las frases a ascii (ya lo hicimos arriba) y escapamos\n",
    "    # usamos boundaries \\b para evitar quitar partes dentro de otras palabras\n",
    "    escaped = [re.escape(r) for r in removes if r]\n",
    "    if escaped:\n",
    "        pattern = r\"\\b(?:\" + \"|\".join(escaped) + r\")\\b\"\n",
    "        s = re.sub(pattern, \" \", s, flags=re.IGNORECASE)\n",
    "\n",
    "    # remover múltiples espacios y strip final\n",
    "    s = re.sub(r\"\\s+\", \" \", s).strip()\n",
    "    return s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbd93a33-81cf-4aa6-8f9d-260ab8d0b229",
   "metadata": {},
   "outputs": [],
   "source": [
    "def crear_imagenes_con_lineas(promedios):\n",
    "    output_dir = \"./imagenes_con_lineas\"\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "    \n",
    "    for img_path in image_files:\n",
    "        img = cv2.imread(img_path)\n",
    "        if img is None:\n",
    "            print(f\"❌ No se pudo leer: {img_path}\")\n",
    "            continue\n",
    "    \n",
    "        # Obtener dimensiones\n",
    "        height, width, _ = img.shape\n",
    "    \n",
    "        # Dibujar cada línea\n",
    "        for x in promedios:\n",
    "            color = (0, 255, 0)  # Verde\n",
    "            thickness = 2\n",
    "            cv2.line(img, (int(x), 0), (int(x), height), color, thickness)\n",
    "    \n",
    "        # Guardar nueva imagen\n",
    "        output_path = os.path.join(output_dir, os.path.basename(img_path))\n",
    "        cv2.imwrite(output_path, img)\n",
    "        print(f\"✅ Guardada: {output_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b860374-a5d4-4fda-9492-e3942799fd6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_texts = {}\n",
    "\n",
    "promedios = [120,680,800]\n",
    "\n",
    "resp = input(\"¿Deseas continuar? (s/n): \").strip().lower()\n",
    "if resp in (\"s\", \"si\", \"y\", \"yes\"):\n",
    "    print(\"Usuario dijo SÍ\")\n",
    "    crear_imagenes_con_lineas(promedios)\n",
    "else:\n",
    "    print(\"Usuario dijo NO\")\n",
    "\n",
    "for img_path in image_files[:10]:\n",
    "    print(img_path)\n",
    "    res = ocr.predict(img_path)\n",
    "\n",
    "    df_to_add = ocr_to_multidimensional_sections(res[0], line_gap=6.5, cortes=promedios)\n",
    "    #print(df_to_add)\n",
    "    all_texts[os.path.basename(img_path)] = df_to_add\n",
    "#print(all_texts)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3837ed2-356e-49fc-b16c-51202241a5e0",
   "metadata": {},
   "source": [
    "# Guardar todo en un solo Excel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ded0eb9-73d6-44b4-8ff2-b32bad3fd940",
   "metadata": {},
   "outputs": [],
   "source": [
    "excel_path = \"ocr_resultado_completo.xlsx\"\n",
    "\n",
    "# Concatenar todos los DataFrames en uno solo\n",
    "final_df = pd.concat(all_texts.values(), ignore_index=True)\n",
    "\n",
    "# Eliminar filas donde TODAS las columnas estén vacías o con espacios\n",
    "final_df = final_df.replace(r'^\\s*$', np.nan, regex=True)  # convierte espacios en NaN\n",
    "final_df = final_df.dropna(how='all')  # elimina filas donde todo es NaN\n",
    "\n",
    "resp_save_original = input(\"¿Deseas continuar? (s/n): \").strip().lower()\n",
    "if resp_save_original in (\"s\", \"si\", \"y\", \"yes\"):\n",
    "    print(\"Usuario dijo SÍ\")\n",
    "    final_df.to_excel(\"ocr_origen.xlsx\", index=False, header=False)\n",
    "else:\n",
    "    print(\"Usuario dijo NO\")\n",
    "\n",
    "#------------------- Rellenar con Año si esta Presente --------------------\n",
    "\n",
    "def separar_anio_y_resto(texto):\n",
    "    if not isinstance(texto, str):\n",
    "        return np.nan, texto\n",
    "    partes = texto.strip().split(maxsplit=1)\n",
    "    if len(partes) == 0:\n",
    "        return np.nan, texto\n",
    "    primer = partes[0]\n",
    "    resto = partes[1] if len(partes) > 1 else \"\"\n",
    "    if primer.isdigit() and 1900 <= int(primer) <= 2099:\n",
    "        return primer, resto\n",
    "    return np.nan, texto\n",
    "\n",
    "# Copiamos el DataFrame original\n",
    "df = final_df.copy()\n",
    "\n",
    "# Detectamos año y resto\n",
    "anio_resto = df[1].apply(lambda x: pd.Series(separar_anio_y_resto(x)))\n",
    "df[\"año\"] = anio_resto[0]\n",
    "df[\"texto\"] = anio_resto[1]\n",
    "\n",
    "# Propagamos el año hacia abajo\n",
    "df[\"año\"] = df[\"año\"].ffill()\n",
    "\n",
    "# Detectamos modelo y versión\n",
    "modelos = []\n",
    "versiones = []\n",
    "modelo_actual = None\n",
    "\n",
    "for texto in df[\"texto\"]:\n",
    "    if isinstance(texto, str) and texto.strip() != \"\":\n",
    "        # Si el texto es una palabra corta (como \"MDX\", \"RDX\", etc.)\n",
    "        # o proviene de una fila con año, lo tomamos como modelo\n",
    "        if len(texto.split()) <= 3:  # criterio: texto corto → modelo\n",
    "            modelo_actual = texto.strip()\n",
    "            modelos.append(modelo_actual)\n",
    "            versiones.append(np.nan)\n",
    "        else:\n",
    "            # Si ya hay un modelo actual, esta fila es una versión de ese modelo\n",
    "            modelos.append(modelo_actual)\n",
    "            versiones.append(texto.strip())\n",
    "    else:\n",
    "        modelos.append(modelo_actual)\n",
    "        versiones.append(np.nan)\n",
    "\n",
    "df[\"modelo\"] = modelos\n",
    "df[\"version\"] = versiones\n",
    "\n",
    "# 4️⃣ Reordenamos columnas\n",
    "columnas_ordenadas = [\"año\", \"modelo\", \"version\"] + [\n",
    "    col for col in df.columns if col not in [0, 1, \"texto\", \"modelo\", \"version\", \"año\"]\n",
    "]\n",
    "\n",
    "excel_df = df[columnas_ordenadas]\n",
    "\n",
    "# Mostrar resultado\n",
    "display(excel_df)\n",
    "\n",
    "## Guardar en una sola hoja\n",
    "excel_df.to_excel(excel_path, index=False, header=False)\n",
    "\n",
    "print(f\"¡Listo! Todo guardado en {excel_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d43cc570-203b-4b42-9a25-36ec6a5ed139",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
