{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ff38bbbc-c227-475c-9181-97ff56f5d977",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Librerias Cargadas\n"
     ]
    }
   ],
   "source": [
    "from paddleocr import PaddleOCR\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import unicodedata\n",
    "import json\n",
    "import re\n",
    "import cv2\n",
    "import os\n",
    "import re\n",
    "\n",
    "pd.set_option('future.no_silent_downcasting', True)\n",
    "\n",
    "print(\"Librerias Cargadas\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2b9ccefe-aec5-45a5-911f-1745cb335035",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/paddle/utils/cpp_extension/extension_utils.py:718: UserWarning: No ccache found. Please be aware that recompiling all source files may be required. You can download and install ccache from: https://github.com/ccache/ccache/blob/master/doc/INSTALL.md\n",
      "  warnings.warn(warning_message)\n",
      "\u001b[32mCreating model: ('PP-LCNet_x1_0_textline_ori', None)\u001b[0m\n",
      "\u001b[32mModel files already exist. Using cached files. To redownload, please delete the directory manually: `/root/.paddlex/official_models/PP-LCNet_x1_0_textline_ori`.\u001b[0m\n",
      "\u001b[32mCreating model: ('PP-OCRv5_server_det', None)\u001b[0m\n",
      "\u001b[32mModel files already exist. Using cached files. To redownload, please delete the directory manually: `/root/.paddlex/official_models/PP-OCRv5_server_det`.\u001b[0m\n",
      "\u001b[32mCreating model: ('latin_PP-OCRv5_mobile_rec', None)\u001b[0m\n",
      "\u001b[32mModel files already exist. Using cached files. To redownload, please delete the directory manually: `/root/.paddlex/official_models/latin_PP-OCRv5_mobile_rec`.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "#ocr = PaddleOCR(\n",
    "#    use_doc_orientation_classify=False, \n",
    " #   use_doc_unwarping=False, \n",
    " #   use_textline_orientation=False) # text detection + text recognition\n",
    "\n",
    "# text image preprocessing + text detection + textline orientation classification + text recognition\n",
    "ocr = PaddleOCR(use_doc_orientation_classify=False, use_doc_unwarping=False, lang=\"es\")\n",
    "\n",
    "# ocr = PaddleOCR(use_doc_orientation_classify=False, use_doc_unwarping=False) # text detection + textline orientation classification + text recognition\n",
    "# ocr = PaddleOCR(\n",
    "#     text_detection_model_name=\"PP-OCRv5_mobile_det\",\n",
    "#     text_recognition_model_name=\"PP-OCRv5_mobile_rec\",\n",
    "#     use_doc_orientation_classify=False,\n",
    "#     use_doc_unwarping=False,\n",
    "#     use_textline_orientation=False) # Switch to PP-OCRv5_mobile models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e8d4cc65-f5e5-4922-8479-307048afdbff",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 Imagenes Cargadas\n"
     ]
    }
   ],
   "source": [
    "image_dir = \"./imagenes\"  # ruta a tu carpeta con imágenes\n",
    "image_extensions = [\".jpg\", \".jpeg\", \".png\", \".bmp\"]\n",
    "\n",
    "# Filtramos solo imágenes\n",
    "image_files = sorted(\n",
    "    [os.path.join(image_dir, f) \n",
    "     for f in os.listdir(image_dir) \n",
    "     if os.path.splitext(f)[1].lower() in image_extensions],\n",
    "    key=lambda x: int(os.path.splitext(os.path.basename(x))[0])\n",
    ")\n",
    "\n",
    "print(str(len(image_files))+\" Imagenes Cargadas\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01532597-82c0-4985-b3b2-9521343dfe8a",
   "metadata": {},
   "source": [
    "# Tal vez mejorar, si se divide con lineas, o limites"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d915f874-1dec-45b7-a670-cf6e909495cb",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def ocr_to_multidimensional_sections(result, line_gap=6.5, cortes=None):\n",
    "    texts = result[\"rec_texts\"]\n",
    "    boxes = result[\"rec_boxes\"]\n",
    "\n",
    "    # Extraer coordenadas y asociar texto\n",
    "    data = []\n",
    "    for text, box in zip(texts, boxes):\n",
    "        x_min, y_min = box[0], box[1]  # esquina superior izq\n",
    "        text = clean_text_simple(text)\n",
    "        data.append({\"text\": text, \"x\": x_min, \"y\": y_min})\n",
    "\n",
    "    # Ordenar primero por Y (vertical) y luego por X (horizontal)\n",
    "    data = sorted(data, key=lambda d: (d[\"y\"], d[\"x\"]))\n",
    "\n",
    "    # Agrupamos por líneas (Y)\n",
    "    ordered_lines = []\n",
    "    current_line = []\n",
    "    last_y = None\n",
    "\n",
    "    for item in data:\n",
    "        if last_y is None or abs(item[\"y\"] - last_y) <= line_gap:\n",
    "            current_line.append(item)\n",
    "        else:\n",
    "            ordered_lines.append(current_line)\n",
    "            current_line = [item]\n",
    "        last_y = item[\"y\"]\n",
    "\n",
    "    if current_line:\n",
    "        ordered_lines.append(current_line)\n",
    "\n",
    "    # Si no se pasan cortes, devolvemos normal\n",
    "    if not cortes:\n",
    "        max_len = max(len(line) for line in ordered_lines)\n",
    "        ordered_filled = [\n",
    "            [i[\"text\"] for i in line] + [\"\"] * (max_len - len(line))\n",
    "            for line in ordered_lines\n",
    "        ]\n",
    "        return pd.DataFrame(ordered_filled)\n",
    "\n",
    "    # --- Usar cortes en X para dividir en secciones ---\n",
    "    cortes = sorted(cortes)  # [178, 286, 373] por ejemplo\n",
    "    n_sections = len(cortes) + 1\n",
    "\n",
    "    all_rows = []\n",
    "    for line in ordered_lines:\n",
    "        row = [\"\"] * n_sections\n",
    "        for item in line:\n",
    "            x = item[\"x\"]\n",
    "            text = item[\"text\"]\n",
    "\n",
    "            # Buscar en qué sección cae\n",
    "            section_idx = 0\n",
    "            for c in cortes:\n",
    "                if x > c:\n",
    "                    section_idx += 1\n",
    "                else:\n",
    "                    break\n",
    "            row[section_idx] += (\" \" + text if row[section_idx] else text)\n",
    "\n",
    "        all_rows.append(row)\n",
    "\n",
    "    df = pd.DataFrame(all_rows)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c4e50d03-aaaa-4189-aaa2-286aed08bd84",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_text_simple(text):\n",
    "    if not isinstance(text, str):\n",
    "        return text\n",
    "     # lista por defecto a eliminar (puedes ampliarla)\n",
    "    default_remove = [\"continua...\", \"continua\", \"ejemplo\", \"borrar\"]\n",
    "    removes = default_remove\n",
    "\n",
    "    s = text.strip()\n",
    "\n",
    "    # normalizar y eliminar diacríticos (á -> a, ñ -> n, etc.)\n",
    "    s = unicodedata.normalize(\"NFKD\", s)\n",
    "    s = s.encode(\"ascii\", \"ignore\").decode(\"ascii\")\n",
    "\n",
    "    # eliminar apostrofes rectos y curvos y guion bajo\n",
    "    s = re.sub(r\"[\\'\\u2019_]\", \"\", s)\n",
    "\n",
    "    # construir patrón para eliminar palabras/frases como palabras completas\n",
    "    # normalizamos las frases a ascii (ya lo hicimos arriba) y escapamos\n",
    "    # usamos boundaries \\b para evitar quitar partes dentro de otras palabras\n",
    "    escaped = [re.escape(r) for r in removes if r]\n",
    "    if escaped:\n",
    "        pattern = r\"\\b(?:\" + \"|\".join(escaped) + r\")\\b\"\n",
    "        s = re.sub(pattern, \" \", s, flags=re.IGNORECASE)\n",
    "\n",
    "    # remover múltiples espacios y strip final\n",
    "    s = re.sub(r\"\\s+\", \" \", s).strip()\n",
    "    return s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "fbd93a33-81cf-4aa6-8f9d-260ab8d0b229",
   "metadata": {},
   "outputs": [],
   "source": [
    "def crear_imagenes_con_lineas(promedios):\n",
    "    output_dir = \"./imagenes_con_lineas\"\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "    \n",
    "    for img_path in image_files:\n",
    "        img = cv2.imread(img_path)\n",
    "        if img is None:\n",
    "            print(f\"❌ No se pudo leer: {img_path}\")\n",
    "            continue\n",
    "    \n",
    "        # Obtener dimensiones\n",
    "        height, width, _ = img.shape\n",
    "    \n",
    "        # Dibujar cada línea\n",
    "        for x in promedios:\n",
    "            color = (0, 255, 0)  # Verde\n",
    "            thickness = 2\n",
    "            cv2.line(img, (int(x), 0), (int(x), height), color, thickness)\n",
    "    \n",
    "        # Guardar nueva imagen\n",
    "        output_path = os.path.join(output_dir, os.path.basename(img_path))\n",
    "        cv2.imwrite(output_path, img)\n",
    "        print(f\"✅ Guardada: {output_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "2b860374-a5d4-4fda-9492-e3942799fd6a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "¿Deseas continuar? (s/n):  s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Usuario dijo SÍ\n",
      "✅ Guardada: ./imagenes_con_lineas/1.jpeg\n",
      "./imagenes/1.jpeg\n"
     ]
    }
   ],
   "source": [
    "all_texts = {}\n",
    "\n",
    "promedios = [120,680,800]\n",
    "\n",
    "resp = input(\"¿Deseas continuar? (s/n): \").strip().lower()\n",
    "if resp in (\"s\", \"si\", \"y\", \"yes\"):\n",
    "    print(\"Usuario dijo SÍ\")\n",
    "    crear_imagenes_con_lineas(promedios)\n",
    "else:\n",
    "    print(\"Usuario dijo NO\")\n",
    "\n",
    "for img_path in image_files[:10]:\n",
    "    print(img_path)\n",
    "    res = ocr.predict(img_path)\n",
    "\n",
    "    df_to_add = ocr_to_multidimensional_sections(res[0], line_gap=6.5, cortes=promedios)\n",
    "    #print(df_to_add)\n",
    "    all_texts[os.path.basename(img_path)] = df_to_add\n",
    "#print(all_texts)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3837ed2-356e-49fc-b16c-51202241a5e0",
   "metadata": {},
   "source": [
    "# Guardar todo en un solo Excel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "9ded0eb9-73d6-44b4-8ff2-b32bad3fd940",
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "¿Deseas continuar? (s/n):  s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Usuario dijo SÍ\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>año</th>\n",
       "      <th>modelo</th>\n",
       "      <th>version</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NaN</td>\n",
       "      <td>BMW</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NaN</td>\n",
       "      <td>BMW</td>\n",
       "      <td>NaN</td>\n",
       "      <td>V</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2018</td>\n",
       "      <td>X5 ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2018</td>\n",
       "      <td>X5 ...</td>\n",
       "      <td>5p xDrive 50i Security Plus V8/4.4/T Aut</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2018</td>\n",
       "      <td>X5 ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1,214,000</td>\n",
       "      <td>1,076,000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65</th>\n",
       "      <td>2024</td>\n",
       "      <td>X6</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66</th>\n",
       "      <td>2024</td>\n",
       "      <td>X6</td>\n",
       "      <td>5p xDrive,40j M.Sport L6/3.0/T Aut</td>\n",
       "      <td>1,075,000 1,225,000 1,320,000 1,504,000</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67</th>\n",
       "      <td>2024</td>\n",
       "      <td>5p M601 V8/4.4/TAut</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1,729,000 1,970,000</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68</th>\n",
       "      <td>2024</td>\n",
       "      <td>5p M601 V8/4.4/TAut</td>\n",
       "      <td>5p M Competition V8/4.4/T Aut</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69</th>\n",
       "      <td>2024</td>\n",
       "      <td>5p M601 V8/4.4/TAut</td>\n",
       "      <td>DEDUCIR EL COSTO DE REACONDICIONAMIENTO</td>\n",
       "      <td>NaN</td>\n",
       "      <td>61</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>70 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     año               modelo                                   version  \\\n",
       "0    NaN                  BMW                                       NaN   \n",
       "1    NaN                  BMW                                       NaN   \n",
       "2   2018               X5 ...                                       NaN   \n",
       "3   2018               X5 ...  5p xDrive 50i Security Plus V8/4.4/T Aut   \n",
       "4   2018               X5 ...                                       NaN   \n",
       "..   ...                  ...                                       ...   \n",
       "65  2024                   X6                                       NaN   \n",
       "66  2024                   X6        5p xDrive,40j M.Sport L6/3.0/T Aut   \n",
       "67  2024  5p M601 V8/4.4/TAut                                       NaN   \n",
       "68  2024  5p M601 V8/4.4/TAut             5p M Competition V8/4.4/T Aut   \n",
       "69  2024  5p M601 V8/4.4/TAut   DEDUCIR EL COSTO DE REACONDICIONAMIENTO   \n",
       "\n",
       "                                          2          3  \n",
       "0                                       NaN        NaN  \n",
       "1                                         V          C  \n",
       "2                                       NaN        NaN  \n",
       "3                                       NaN        NaN  \n",
       "4                                 1,214,000  1,076,000  \n",
       "..                                      ...        ...  \n",
       "65                                      NaN        NaN  \n",
       "66  1,075,000 1,225,000 1,320,000 1,504,000        NaN  \n",
       "67                      1,729,000 1,970,000        NaN  \n",
       "68                                      NaN        NaN  \n",
       "69                                      NaN         61  \n",
       "\n",
       "[70 rows x 5 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "¡Listo! Todo guardado en ocr_resultado_completo.xlsx\n"
     ]
    }
   ],
   "source": [
    "excel_path = \"ocr_resultado_completo.xlsx\"\n",
    "\n",
    "# Concatenar todos los DataFrames en uno solo\n",
    "final_df = pd.concat(all_texts.values(), ignore_index=True)\n",
    "\n",
    "# Eliminar filas donde TODAS las columnas estén vacías o con espacios\n",
    "final_df = final_df.replace(r'^\\s*$', np.nan, regex=True)  # convierte espacios en NaN\n",
    "final_df = final_df.dropna(how='all')  # elimina filas donde todo es NaN\n",
    "\n",
    "resp_save_original = input(\"¿Deseas continuar? (s/n): \").strip().lower()\n",
    "if resp_save_original in (\"s\", \"si\", \"y\", \"yes\"):\n",
    "    print(\"Usuario dijo SÍ\")\n",
    "    final_df.to_excel(\"ocr_origen.xlsx\", index=False, header=False)\n",
    "else:\n",
    "    print(\"Usuario dijo NO\")\n",
    "\n",
    "#------------------- Rellenar con Año si esta Presente --------------------\n",
    "\n",
    "def separar_anio_y_resto(texto):\n",
    "    if not isinstance(texto, str):\n",
    "        return np.nan, texto\n",
    "    partes = texto.strip().split(maxsplit=1)\n",
    "    if len(partes) == 0:\n",
    "        return np.nan, texto\n",
    "    primer = partes[0]\n",
    "    resto = partes[1] if len(partes) > 1 else \"\"\n",
    "    if primer.isdigit() and 1900 <= int(primer) <= 2099:\n",
    "        return primer, resto\n",
    "    return np.nan, texto\n",
    "\n",
    "# Copiamos el DataFrame original\n",
    "df = final_df.copy()\n",
    "\n",
    "# Detectamos año y resto\n",
    "anio_resto = df[1].apply(lambda x: pd.Series(separar_anio_y_resto(x)))\n",
    "df[\"año\"] = anio_resto[0]\n",
    "df[\"texto\"] = anio_resto[1]\n",
    "\n",
    "# Propagamos el año hacia abajo\n",
    "df[\"año\"] = df[\"año\"].ffill()\n",
    "\n",
    "# Detectamos modelo y versión\n",
    "modelos = []\n",
    "versiones = []\n",
    "modelo_actual = None\n",
    "\n",
    "for texto in df[\"texto\"]:\n",
    "    if isinstance(texto, str) and texto.strip() != \"\":\n",
    "        # Si el texto es una palabra corta (como \"MDX\", \"RDX\", etc.)\n",
    "        # o proviene de una fila con año, lo tomamos como modelo\n",
    "        if len(texto.split()) <= 3:  # criterio: texto corto → modelo\n",
    "            modelo_actual = texto.strip()\n",
    "            modelos.append(modelo_actual)\n",
    "            versiones.append(np.nan)\n",
    "        else:\n",
    "            # Si ya hay un modelo actual, esta fila es una versión de ese modelo\n",
    "            modelos.append(modelo_actual)\n",
    "            versiones.append(texto.strip())\n",
    "    else:\n",
    "        modelos.append(modelo_actual)\n",
    "        versiones.append(np.nan)\n",
    "\n",
    "df[\"modelo\"] = modelos\n",
    "df[\"version\"] = versiones\n",
    "\n",
    "# 4️⃣ Reordenamos columnas\n",
    "columnas_ordenadas = [\"año\", \"modelo\", \"version\"] + [\n",
    "    col for col in df.columns if col not in [0, 1, \"texto\", \"modelo\", \"version\", \"año\"]\n",
    "]\n",
    "\n",
    "excel_df = df[columnas_ordenadas]\n",
    "\n",
    "# Mostrar resultado\n",
    "display(excel_df)\n",
    "\n",
    "## Guardar en una sola hoja\n",
    "excel_df.to_excel(excel_path, index=False, header=False)\n",
    "\n",
    "print(f\"¡Listo! Todo guardado en {excel_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d43cc570-203b-4b42-9a25-36ec6a5ed139",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
